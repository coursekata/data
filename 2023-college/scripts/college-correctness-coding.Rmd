---
title: "College Correctness Coding Exercises"
output: html_notebook
---

The purpose of this script is to create

1.  `new_responses_ck_code`, which is a response data file that only includes CK coding exercises

2. CK code correctness metrics, including at the page level:

a) proportion correctness by student by release version by page `student_page_code_prop`
b) proportion correctnesss by page by release version `page_release_code_correct`
c) proportion correctness by page `page_code_correct`

3. CK code correctness metrics at the chapter level:

a) proportion correctness by student by chapter `student_chapter_code_correct`
b) proportion correctness by chapter `chapter_code_correct`


This assumes we start with a basic `responses.csv` file.

In this data processing, we will treat student_id+release as a unique student. If a student responds in two release versions (e.g., 4.2 and 5.0), that student will appear as two cases.

## Set up and load `responses.Rdata`, `codebook_page`, and `codebook_all_surveys`

```{r}
# load libraries
library(mosaic)
library(dplyr)
library(tidyverse)
library(ggplot2)


# start with raw data from responses.Rdata
setwd("~/Desktop/github repository/data/2023-college/raw")
load("../raw/responses.Rdata")


# also load codebook page and codebook_all_surveys
setwd("~/Desktop/github repository/data/2023-college/codebooks")
codebook_page <- read.csv("../codebooks/codebook_page.csv")
codebook_all_surveys <- read.csv("../codebooks/codebook_all_surveys.csv")

```

1.  Create `new_responses_ck_code` - a response data file that only includes CK coding exercises

```{r}
## Merge page_num and chapter_num into responses and read in survey codebook so we can filter out survey responses.

responses_nosurvey <- responses %>%
  left_join(codebook_page, by=c("book", "release", "chapter", "page"))

new_responses_ck_code <- responses_nosurvey[, c("student_id", "class_id", "item_id", "lrn_question_reference", "item_type", "chapter_num", "page_num", "completes_page", "response", "points_possible", "points_earned", "lrn_status", "lrn_type", "lrn_auto", "attempt", "lrn_dt_started", "lrn_dt_saved", "dt_submitted", "book", "release")] %>%
  filter(!(item_id %in% codebook_all_surveys$item_id)) %>%
  filter(!(is.na(page_num))) %>% 
  filter(item_type=="code") 

```


2. Create CK code correctness metrics
# ckcode
## each row is a student + release + coding exercise

```{r}
# each row is going is going to be a student+release+coding exercise
student_code_correct <- new_responses_ck_code %>%
  group_by (student_id, class_id, release, item_id) %>%
  mutate(is_correct_ever = max(points_earned), 
         correct_first_try = ifelse(attempt == 1, points_earned, NA),
         num_attempts=max(attempt),
         num_correct=sum(points_earned, na.rm=TRUE)) %>%
  select(book, student_id, release, item_id, item_type, page_num, chapter_num, class_id, is_correct_ever, correct_first_try, num_attempts, num_correct) %>%
  filter(!is.na(page_num)&!is.na(correct_first_try)) %>% 
  distinct()

```


## 2 a) proportion correctness by student by release version by page- each row is a student + release + page (for coding exercises) 

```{r}
student_page_code_correct <- student_code_correct %>%
  group_by (student_id, class_id, release, chapter_num, page_num) %>%
  mutate(correct_ever_per_page = sum(is_correct_ever, na.rm=TRUE), #per page, how many points_earned on attempt ==1?
         correct_first_try_per_page=sum(correct_first_try, na.rm=TRUE),
         num_attempts_per_page=sum(num_attempts, na.rm=TRUE),
         correct_attempts_per_page=sum(num_correct, na.rm=TRUE)) %>%
  select(book, student_id, release, page_num, chapter_num, class_id, correct_ever_per_page, correct_first_try_per_page, num_attempts_per_page, correct_attempts_per_page) %>%
  distinct()

#write.csv(student_page_code_correct, "../level-page/student_page_code_correct_college.Rdata", row.names = FALSE)

save(student_page_code_correct, file = "student_page_code_correct.Rdata", compress = "xz", compression_level = 9)

```

```{r}

student_page_code_prop <- student_page_code_correct %>%
  left_join(codebook_page, by=c('book', 'release', 'chapter_num', 'page_num')) %>%
  mutate(corr_ever_prop = correct_ever_per_page / n_code, # cannot be greater than 1
         corr_first_prop = correct_first_try_per_page / n_code, # cannot be greater than 1
         attempt_per_code = num_attempts_per_page / n_code, # must be greater than 1, everyone attempts at least once
         corr_attempt_per_code = correct_attempts_per_page / n_code, # can be greater than 1
         corr_rate_per_attempt = correct_attempts_per_page / num_attempts_per_page) # cannot be greater than 1

#write.csv(student_page_code_prop, "student_page_code_prop_college.csv", row.names = FALSE)

save(student_page_code_prop, file = "student_page_code_prop.Rdata", compress = "xz", compression_level = 9)

```


```{r}
# get correctness by page and release version
page_release_code_correct <- student_page_code_correct %>%
  group_by(release, chapter_num, page_num) %>%
  summarize(
    avg_corr_ever_page = mean(correct_ever_per_page, na.rm=TRUE),
    avg_corr_first_try_page = mean(correct_first_try_per_page, na.rm=TRUE),
    avg_attempts_page = mean(num_attempts_per_page, na.rm=TRUE),
    avg_corr_attempts_page = mean(correct_attempts_per_page, na.rm=TRUE),
    #total_n_code_page = sum(n_code_page)
  )

```


```{r}
# get correctness PROPORTION by page and release version
page_release_code_prop <- student_page_code_prop %>%
  group_by(release, chapter_num, page_num ) %>%
  summarize(
    avg_corr_ever_prop = mean(corr_ever_prop, na.rm=TRUE),
    avg_corr_first_prop = mean(corr_first_prop, na.rm=TRUE),
    avg_attempts_code_prop = mean(attempt_per_code, na.rm=TRUE),
    avg_corr_attempt_prop = mean(correct_attempts_per_page), na.rm=TRUE,
    avg_corr_rate_per_attempt = mean(corr_rate_per_attempt, na.rm=TRUE),
    total_n_code_page = sum(n_code)
  )

```


```{r}
# get correctness by page ACROSS release version (i.e., summary)
page_code_prop <- page_release_code_prop %>%
  group_by(chapter_num, page_num) %>%
  summarize(
    page_corr_ever_prop = mean(avg_corr_ever_prop, na.rm=TRUE),
    page_corr_first_prop = mean(avg_corr_first_prop, na.rm=TRUE),
    page_avg_attempts_code_prop = mean(avg_attempts_code_prop, na.rm=TRUE),
    page_avg_corr_attempt_prop = mean(avg_corr_attempt_prop, na.rm=TRUE),
    page_avg_corr_rate_per_attempt = mean(avg_corr_rate_per_attempt, na.rm=TRUE),
    #total_n_code_page = sum(n_code)
  )


# save file
#write.csv(page_code_prop, "page_code_prop_college.csv", row.names = FALSE)
save(page_code_prop, file = "page_code_prop.Rdata", compress = "xz", compression_level = 9)

```


3. CK code correctness metrics at the chapter level:
## each row is a student + release + chapter (for coding exercises)

```{r}
#codebook for chapter

codebook_ch <- codebook_page %>%
  group_by(book, release, chapter_num) %>%
  mutate(n_code_ch = sum(n_code,  na.rm = TRUE)) %>%
  select(book, release, chapter_num, n_code_ch) %>%
  distinct()
```

```{r}
student_chapter_code_correct <- student_page_code_correct %>%
  group_by(student_id, class_id, release, chapter_num) %>%
  mutate(corr_ever_per_ch = sum(correct_ever_per_page, na.rm=TRUE),
         corr_first_try_per_ch = sum(correct_first_try_per_page, na.rm=TRUE),
         attempts_per_ch = sum(num_attempts_per_page, na.rm=TRUE),
         corr_attempts_per_ch = sum(correct_attempts_per_page, na.rm=TRUE)) %>%
  left_join(codebook_ch, by = c("book", "release", "chapter_num")) %>%
  mutate(corr_ever_prop = corr_ever_per_ch / n_code_ch, # cannot be greater than 1
         corr_first_prop = corr_first_try_per_ch / n_code_ch, # cannot be greater than 1
         attempts_per_ch_prop = attempts_per_ch / n_code_ch, # must be greater than 1, everyone attempts at least once
         corr_attempt_per_ch_prop = corr_attempts_per_ch / n_code_ch, # can be greater than 1
         corr_rate_per_attempt_ch = corr_attempt_per_ch_prop / attempts_per_ch_prop) %>% # cannot be greater than 1
  select(student_id, class_id, release, n_code_ch, chapter_num, corr_ever_per_ch, corr_first_try_per_ch, attempts_per_ch,
         corr_attempts_per_ch, corr_ever_prop, corr_first_prop, attempts_per_ch_prop, corr_attempt_per_ch_prop,
         corr_rate_per_attempt_ch) %>%
  distinct()

#save file 
#write.csv(student_chapter_code_correct, "student_chapter_code_correct_college.csv", row.names = FALSE)

save(student_chapter_code_correct, file = "student_chapter_code_correct.Rdata", compress = "xz", compression_level = 9)
```

```{r}
# get correctness by chapter and release version
chapter_release_code_correct <- student_chapter_code_correct %>%
  group_by(chapter_num,release ) %>%
  summarize(
    total_corr_ever = sum(corr_ever_per_ch, na.rm=TRUE),
    total_corr_first_try = sum(corr_first_try_per_ch, na.rm=TRUE),
    total_attempts = sum(attempts_per_ch, na.rm=TRUE),
    total_corr_attempts = sum(corr_attempts_per_ch, na.rm=TRUE),
    avg_corr_ever_prop = mean(corr_ever_prop, na.rm=TRUE),
    avg_corr_first_prop = mean(corr_first_prop, na.rm=TRUE),
    avg_attempts_prop = mean(attempts_per_ch_prop, na.rm=TRUE),
    avg_corr_attempt_prop = mean(corr_attempt_per_ch_prop, na.rm=TRUE),
    avg_corr_rate_per_attempt = mean(corr_rate_per_attempt_ch, na.rm=TRUE),
    total_n_code_ch = sum(n_code_ch)
  )

#write.csv(chapter_release_code_correct, "chapter_release_code_correct_college.csv", row.names = FALSE)
```



```{r}
# Get averages by chapter_num only
chapter_code_correct <- chapter_release_code_correct %>%
  group_by(chapter_num) %>%
  summarize(
    ch_avg_corr_ever_prop = mean(avg_corr_ever_prop, na.rm=TRUE),
    ch_avg_corr_first_prop = mean(avg_corr_first_prop, na.rm=TRUE),
    ch_avg_attempts_prop = mean(avg_attempts_prop, na.rm=TRUE),
    ch_avg_corr_attempt_prop = mean(avg_corr_attempt_prop, na.rm=TRUE),
    ch_avg_corr_rate_per_attempt = mean(avg_corr_rate_per_attempt, na.rm=TRUE),
    #total_n_code_ch = sum(n_code_ch)
  )

#save data
#write.csv(chapter_code_correct, "chapter_code_correct_college.csv", row.names = FALSE)
save(chapter_code_correct, file = "chapter_code_correct.Rdata", compress = "xz", compression_level = 9)
```


